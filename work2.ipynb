{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização das imagens filtered entre 0 e 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "def normalize_img(image):\n",
    "    imagem = sitk.ReadImage(\"images_filtered/IXI002-Guys-0828-T1.nii.gz\")\n",
    "    img_np = sitk.GetArrayFromImage(imagem)\n",
    "\n",
    "    data_min = np.min(img_np)\n",
    "    data_max = np.max(img_np)\n",
    "    normalized_data = (img_np - data_min) / (data_max - data_min) * 255\n",
    "    normalized_data = normalized_data.astype(np.uint8)\n",
    "    image_norm = sitk.GetImageFromArray(normalized_data)\n",
    "    return image_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_directories(directory, img=None):\n",
    "    # Get a list of filenames in the specified directory\n",
    "    filenames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if img is not None:\n",
    "            # If 'img' is provided, filter filenames containing it\n",
    "            if img in filename:   \n",
    "                filenames.append(filename)          \n",
    "        else:\n",
    "            filenames.append(filename)    \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando as imagens filtradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_images\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m name_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m image_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_img\u001b[49m(path)\n\u001b[0;32m     10\u001b[0m sitk\u001b[38;5;241m.\u001b[39mWriteImage(image_normalized, name_out)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalize_img' is not defined"
     ]
    }
   ],
   "source": [
    "dir_images = f'images_filtered'\n",
    "array_images = read_directories(dir_images)\n",
    "dir_out = f'normalizeds'\n",
    "\n",
    "\n",
    "for image in array_images:\n",
    "    path = f'{dir_images}/{image}'\n",
    "    name_out = f'{dir_out}/{image}'\n",
    "    image_normalized = normalize_img(path)\n",
    "    sitk.WriteImage(image_normalized, name_out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out = f'normalizeds'\n",
    "array_normalizeds = read_directories(dir_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo as médias dos valores de CSF, GM e WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "def calc_means_csf_gm_wm(path):\n",
    "    #imagem que vai ser usada como teste\n",
    "    imagem = sitk.ReadImage(f\"normalizeds/{path}\")\n",
    "    img_np = sitk.GetArrayFromImage(imagem)\n",
    "\n",
    "\n",
    "    atlas_csf = sitk.ReadImage(f\"atlas_resampled/{path}/mni_csf.nii.gz\")\n",
    "    atlas_gm = sitk.ReadImage(f\"atlas_resampled/{path}/mni_gm.nii.gz\")\n",
    "    atlas_wm = sitk.ReadImage(f\"atlas_resampled/{path}/mni_wm.nii.gz\")\n",
    "\n",
    "    atlas_csf_array = sitk.GetArrayFromImage(atlas_csf)\n",
    "    atlas_gm_array = sitk.GetArrayFromImage(atlas_gm)\n",
    "    atlas_wm_array = sitk.GetArrayFromImage(atlas_wm)\n",
    "\n",
    "    binary_array_csf = (atlas_csf_array > 0.98).astype(np.uint8)\n",
    "    binary_array_gm = (atlas_gm_array > 0.98).astype(np.uint8)\n",
    "    binary_array_wm = (atlas_wm_array > 0.98).astype(np.uint8)\n",
    "\n",
    "    # Converter de volta para imagem SimpleITK\n",
    "    binary_image_csf = sitk.GetImageFromArray(binary_array_csf)\n",
    "    binary_image_csf.CopyInformation(atlas_csf)  # Mantém metadados da imagem original\n",
    "\n",
    "    binary_image_gm = sitk.GetImageFromArray(binary_array_gm)\n",
    "    binary_image_gm.CopyInformation(atlas_gm)  # Mantém metadados da imagem original\n",
    "\n",
    "    binary_image_wm = sitk.GetImageFromArray(binary_array_wm)\n",
    "    binary_image_wm.CopyInformation(atlas_wm)  # Mantém metadados da imagem original\n",
    "\n",
    "    mask_np_csf = (binary_array_csf > 0).astype(np.uint8)\n",
    "    mask_np_gm = (binary_array_gm > 0).astype(np.uint8)\n",
    "    mask_np_wm = (binary_array_wm > 0).astype(np.uint8)\n",
    "\n",
    "    result_np_csf = (img_np * mask_np_csf)\n",
    "    result_np_gm = (img_np * mask_np_gm)\n",
    "    result_np_wm = (img_np * mask_np_wm)\n",
    "\n",
    "    vetor_np_csf = result_np_csf[result_np_csf>0]\n",
    "    vetor_np_csf_mean = np.mean(vetor_np_csf)\n",
    "    print(f\"Vetor final média csf: {vetor_np_csf_mean}.\")\n",
    "\n",
    "    vetor_np_gm = result_np_gm[result_np_gm>0]\n",
    "    vetor_np_gm_mean = np.mean(vetor_np_gm)\n",
    "    print(f\"Vetor final média gm: {vetor_np_gm_mean}.\")\n",
    "\n",
    "\n",
    "    vetor_np_wm = result_np_wm[result_np_wm>0]\n",
    "    vetor_np_wm_mean = np.mean(vetor_np_wm)\n",
    "    print(f\"Vetor final média wm: {vetor_np_wm_mean}.\")\n",
    "\n",
    "\n",
    "    dict = {\n",
    "        'CSF':vetor_np_csf_mean,\n",
    "        'GM':vetor_np_gm_mean,\n",
    "        'WM':vetor_np_wm_mean\n",
    "    }\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar o kmeans com as três médias advindas das imagens. Fazer a clusterização da imagem original mediante as três médias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output_segmented = f'segmenteds'\n",
    "\n",
    "for image in array_normalizeds:\n",
    "    # --- Carregar a imagem original ---\n",
    "    image_path = f\"normalizeds\\{image}\"  # Modifique para o caminho da sua imagem\n",
    "    nifti_image = nib.load(image_path)\n",
    "    image_data = nifti_image.get_fdata()  # Array NumPy da imagem\n",
    "\n",
    "    # --- Carregar a máscara ---\n",
    "    mask_path = f\"atlas_resampled\\{image}\\mni_mask.nii.gz\"  # Caminho do arquivo enviado\n",
    "    mask_nifti = nib.load(mask_path)\n",
    "    mask_data = mask_nifti.get_fdata()  # Array NumPy da máscara\n",
    "\n",
    "    # --- Aplicar a máscara (mantendo apenas a parte branca) ---\n",
    "    image_data[mask_data == 0] = 0\n",
    "\n",
    "    # Obter o tamanho do voxel em mm (dimensão do voxel)\n",
    "    voxel_size = np.prod(nifti_image.header.get_zooms())  # Multiplica (dx, dy, dz) para obter mm³\n",
    "\n",
    "    dicionario = calc_means_csf_gm_wm(image)\n",
    "    vetor_np_csf_mean = dicionario['CSF']\n",
    "    print(f'vetor_np_csf_mean: {vetor_np_csf_mean}')\n",
    "\n",
    "    vetor_np_gm_mean = dicionario['GM']\n",
    "    print(f'vetor_np_gm_mean: {vetor_np_gm_mean}')\n",
    "    \n",
    "    vetor_np_wm_mean = dicionario['WM']\n",
    "    print(f'vetor_np_wm_mean: {vetor_np_wm_mean}')\n",
    "\n",
    "    # Definir as médias fornecidas para os 3 clusters\n",
    "    cluster_means = np.array([[vetor_np_csf_mean], [vetor_np_gm_mean], [vetor_np_wm_mean]])  # Exemplo de valores médios\n",
    "\n",
    "    # Número de clusters\n",
    "    k = len(cluster_means)\n",
    "\n",
    "    # Inicializar centroides com as médias fornecidas\n",
    "    centroids = cluster_means.copy()\n",
    "\n",
    "    # Função para atribuir cada pixel ao cluster mais próximo\n",
    "    def assign_to_cluster(image_data, centroids):\n",
    "        distances = np.abs(image_data[..., None] - centroids.flatten())\n",
    "        return np.argmin(distances, axis=-1)\n",
    "\n",
    "    # Função para atualizar os centroids\n",
    "    def update_centroids(image_data, labels, k):\n",
    "        new_centroids = np.zeros(k)\n",
    "        for i in range(k):\n",
    "            if np.any(labels == i):\n",
    "                new_centroids[i] = np.mean(image_data[labels == i])\n",
    "            else:\n",
    "                new_centroids[i] = centroids[i]  # Mantém se não houver atualização\n",
    "                print(f'centroid[i]: {centroids[i]}')\n",
    "        return new_centroids\n",
    "\n",
    "    # Número máximo de iterações\n",
    "    max_iters = 100\n",
    "    tolerance = 1e-4\n",
    "    prev_centroids = np.zeros_like(centroids)\n",
    "\n",
    "    # Iteração do K-means\n",
    "    for iteration in range(max_iters):\n",
    "        labels = assign_to_cluster(image_data, centroids)\n",
    "        centroids = update_centroids(image_data, labels, k)\n",
    "        \n",
    "        if np.all(np.abs(centroids - prev_centroids) < tolerance):\n",
    "            print(f\"Convergência atingida após {iteration + 1} iterações.\")\n",
    "            break\n",
    "        \n",
    "        prev_centroids = centroids.copy()\n",
    "\n",
    "    # Criar uma imagem RGB para visualização\n",
    "    segmented_rgb = np.zeros((*labels.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    # Definir as cores (R, G, B)\n",
    "    colors = {\n",
    "        0: [255, 0, 0],      # Vermelho (Primeira classe)\n",
    "        1: [128, 128, 128],      # Cinza (Segunda classe)\n",
    "        2: [255, 255, 255],  # Branco (Terceira classe)       \n",
    "    }\n",
    "\n",
    "    # Atribuir cores aos pixels classificados\n",
    "    for class_id, color in colors.items():\n",
    "        segmented_rgb[labels == class_id] = color\n",
    "\n",
    "    # Aplicar a máscara na segmentação (fundo preto)\n",
    "    segmented_rgb[mask_data == 0] = [0, 0, 0]\n",
    "\n",
    "    # Mostrar um corte da segmentação\n",
    "    slice_index = segmented_rgb.shape[0] // 2  # Pegar um corte no meio\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(segmented_rgb[slice_index])  # Mostrar a imagem colorida\n",
    "    plt.title(\"Segmentação K-means com máscara aplicada\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    #nib.save(segmented_rgb,filename='segmented_rgb.nii.gz')\n",
    "\n",
    "    # --- Cálculo do Volume ---\n",
    "    volumes = {}\n",
    "    for class_id in range(k):\n",
    "        num_voxels = np.sum(labels == class_id)  # Contar número de voxels na classe\n",
    "        volume_mm3 = num_voxels * voxel_size  # Multiplicar pelo tamanho do voxel\n",
    "        volumes[class_id] = volume_mm3\n",
    "\n",
    "    # Exibir resultados\n",
    "    print(\"\\nVolumes calculados:\")\n",
    "    for class_id, volume in volumes.items():\n",
    "        print(f\"Classe {class_id} ({['CSF', 'GM', 'WM'][class_id]}): {volume:.2f} mm³\")\n",
    "\n",
    "    segmented_nifti = nib.Nifti1Image(segmented_rgb, affine=nifti_image.affine, header=nifti_image.header)\n",
    "\n",
    "    \n",
    "    # --- Salvar a imagem segmentada ---\n",
    "    nib.save(segmented_nifti, f'{dir_output_segmented}/{image}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o Kmeans com valores setados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def calc_means_csf_gm_wm(image):\n",
    "    return {'CSF': 104, 'GM': 64, 'WM': 40}\n",
    "\n",
    "dir_output_segmented = 'segmenteds'\n",
    "\n",
    "for i in range(1):\n",
    "    image_path = f\"normalizeds/{array_normalizeds[0]}\"\n",
    "    mask_path = f\"atlas_resampled/{array_normalizeds[0]}/mni_mask.nii.gz\"\n",
    "\n",
    "    nifti_image = nib.load(image_path)\n",
    "    image_data = nifti_image.get_fdata()\n",
    "    \n",
    "    mask_nifti = nib.load(mask_path)\n",
    "    mask_data = mask_nifti.get_fdata()\n",
    "    \n",
    "    image_data[mask_data == 0] = 0\n",
    "    voxel_size = np.prod(nifti_image.header.get_zooms())\n",
    "    \n",
    "    dicionario = calc_means_csf_gm_wm(array_normalizeds[0])\n",
    "    cluster_means = np.array([dicionario['CSF'], dicionario['GM'], dicionario['WM'], 0])\n",
    "    print(f'cluster_means: {cluster_means}')\n",
    "    k = len(cluster_means)\n",
    "    centroids = cluster_means.copy()\n",
    "    \n",
    "    def assign_to_cluster(image_data, centroids):\n",
    "        distances = np.abs(image_data[..., None] - centroids.flatten())\n",
    "        return np.argmin(distances, axis=-1)\n",
    "    \n",
    "    def update_centroids(image_data, labels, k):\n",
    "        new_centroids = np.zeros(k)\n",
    "        for i in range(k):\n",
    "            if np.any(labels == i):\n",
    "                new_centroids[i] = np.mean(image_data[labels == i])\n",
    "            else:\n",
    "                new_centroids[i] = centroids[i]\n",
    "        return new_centroids\n",
    "    \n",
    "    max_iters = 100\n",
    "    tolerance = 1e-4\n",
    "    prev_centroids = np.zeros_like(centroids)\n",
    "    \n",
    "    for iteration in range(max_iters):\n",
    "        labels = assign_to_cluster(image_data, centroids)\n",
    "        centroids = update_centroids(image_data, labels, k)\n",
    "        \n",
    "        if np.all(np.abs(centroids - prev_centroids) < tolerance):\n",
    "            break\n",
    "        prev_centroids = centroids.copy()\n",
    "    \n",
    "    segmented_rgb = np.zeros((*labels.shape, 4), dtype=np.uint8)\n",
    "    colors = {\n",
    "        0: [255, 0, 0, 255],      # Vermelho (Primeira classe)\n",
    "        1: [128, 128, 128, 255],  # Cinza (Segunda classe)\n",
    "        2: [255, 255, 255, 255],  # Branco (Terceira classe)\n",
    "        3: [0, 255, 0, 255]       # Verde (Quarta classe - lixo)\n",
    "    }\n",
    "    \n",
    "    for class_id, color in colors.items():\n",
    "        segmented_rgb[labels == class_id] = color\n",
    "    \n",
    "    segmented_rgb[mask_data == 0] = [0, 0, 0, 0]\n",
    "    \n",
    "    slice_index = segmented_rgb.shape[0] // 2\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(segmented_rgb[slice_index])\n",
    "    plt.title(\"Segmentação K-means com máscara aplicada\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    volumes = {}\n",
    "    for class_id in range(k):\n",
    "        num_voxels = np.sum(labels == class_id)\n",
    "        volume_mm3 = num_voxels * voxel_size\n",
    "        volumes[class_id] = volume_mm3\n",
    "    \n",
    "    print(\"\\nVolumes calculados:\")\n",
    "    for class_id, volume in volumes.items():\n",
    "        print(f\"Classe {class_id} ({['CSF', 'GM', 'WM', 'lixo'][class_id]}): {volume:.2f} mm³\")\n",
    "    \n",
    "    segmented_nifti = nib.Nifti1Image(segmented_rgb, affine=nifti_image.affine, header=nifti_image.header)\n",
    "    os.makedirs(dir_output_segmented, exist_ok=True)\n",
    "    nib.save(segmented_nifti, f'{dir_output_segmented}/{array_normalizeds[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o Kmeans++ com imagens normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "# --- Carregar a imagem original ---\n",
    "image_path = \"normalizeds\\IXI002-Guys-0828-T1.nii.gz\"  \n",
    "nifti_image = nib.load(image_path)\n",
    "image_data = nifti_image.get_fdata()\n",
    "\n",
    "# --- Carregar a máscara ---\n",
    "mask_path = \"atlas_resampled\\IXI002-Guys-0828-T1.nii.gz\\mni_mask.nii.gz\"\n",
    "mask_nifti = nib.load(mask_path)\n",
    "mask_data = mask_nifti.get_fdata()\n",
    "\n",
    "# --- Aplicar a máscara (mantendo apenas a parte branca) ---\n",
    "image_data[mask_data == 0] = 0\n",
    "\n",
    "# Obter o tamanho do voxel em mm³ (dimensão do voxel)\n",
    "voxel_size = np.prod(nifti_image.header.get_zooms())\n",
    "\n",
    "# Número de clusters (3 classes + 1 classe \"lixo\")\n",
    "k = 4\n",
    "\n",
    "# --- Inicialização dos centróides com K-means++ ---\n",
    "def initialize_kmeans_pp(data, k):\n",
    "    \"\"\"\n",
    "    Inicializa os centróides usando o método K-means++\n",
    "    \"\"\"\n",
    "    data_flat = data[mask_data > 0].flatten()  # Apenas valores dentro da máscara\n",
    "    centroids = [np.random.choice(data_flat)]  # Escolher o primeiro aleatoriamente\n",
    "    print(f' centroid inicial: { centroids}')\n",
    "    \n",
    "    for _ in range(1, k - 1):  # Deixar uma classe reservada para valores próximos de zero\n",
    "        distances = np.min([np.abs(data_flat - c) for c in centroids], axis=0)\n",
    "        probabilities = distances ** 2  # Quanto maior a distância, maior a chance de escolha\n",
    "        probabilities /= np.sum(probabilities)  # Normalizar\n",
    "        \n",
    "        new_centroid = np.random.choice(data_flat, p=probabilities)\n",
    "        centroids.append(new_centroid)\n",
    "    \n",
    "    centroids.append(0)  # Classe \"lixo\" para valores próximos de zero\n",
    "    \n",
    "    return np.array(centroids)\n",
    "\n",
    "# Inicializa os centróides\n",
    "centroids = initialize_kmeans_pp(image_data, k)\n",
    "\n",
    "# --- Função para atribuir cada pixel ao cluster mais próximo ---\n",
    "def assign_to_cluster(image_data, centroids):\n",
    "    distances = np.abs(image_data[..., None] - centroids.flatten())\n",
    "    return np.argmin(distances, axis=-1)\n",
    "\n",
    "# --- Função para atualizar os centroids ---\n",
    "def update_centroids(image_data, labels, k):\n",
    "    new_centroids = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        if np.any((labels == i) & (mask_data > 0)) and i != k - 1:  # Apenas valores dentro da máscara\n",
    "            new_centroids[i] = np.mean(image_data[(labels == i) & (mask_data > 0)])\n",
    "            print(f' new_centroids {[i]}: { new_centroids[i]}')\n",
    "        else:\n",
    "            new_centroids[i] = centroids[i]  # Mantém o valor se não houver atualização\n",
    "            print(f'centroids {[i]}: {centroids[i]}')\n",
    "            print(f' new_centroids {[i]}: { new_centroids[i]}')\n",
    "    return new_centroids\n",
    " \n",
    "\n",
    "# Número máximo de iterações\n",
    "max_iters = 100\n",
    "tolerance = 1e-4\n",
    "prev_centroids = np.zeros_like(centroids)\n",
    "\n",
    "# --- Iteração do K-means ---\n",
    "for iteration in range(max_iters):\n",
    "    labels = assign_to_cluster(image_data, centroids)\n",
    "    centroids = update_centroids(image_data, labels, k)\n",
    "    \n",
    "    if np.all(np.abs(centroids - prev_centroids) < tolerance):\n",
    "        print(f\"Convergência atingida após {iteration + 1} iterações.\")\n",
    "        break\n",
    "    \n",
    "    prev_centroids = centroids.copy()\n",
    "\n",
    "# Criar uma imagem RGB para visualização\n",
    "segmented_rgb = np.zeros((*labels.shape, 3), dtype=np.uint8)\n",
    "\n",
    "# Definir as cores (R, G, B)\n",
    "colors = {\n",
    "    0: [255, 0, 0],      # CSF\n",
    "    1: [128, 128, 128],      # GM\n",
    "    2: [255, 255, 255],  # WM\n",
    "    3: [0, 0,  0],  # Preto\n",
    "}\n",
    "\n",
    "# Atribuir cores aos pixels classificados\n",
    "for class_id, color in colors.items():\n",
    "    segmented_rgb[labels == class_id] = color\n",
    "\n",
    "# Aplicar a máscara na segmentação (fundo preto)\n",
    "segmented_rgb[mask_data == 0] = [0, 0, 0]\n",
    "\n",
    "# Mostrar um corte da segmentação\n",
    "slice_index = segmented_rgb.shape[0] // 2\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(segmented_rgb[slice_index])\n",
    "plt.title(\"Segmentação K-means++ com máscara aplicada\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# --- Cálculo do Volume ---\n",
    "volumes = {}\n",
    "for class_id in range(k):\n",
    "    num_voxels = np.sum((labels == class_id) & (mask_data > 0))\n",
    "    volume_mm3 = num_voxels * voxel_size\n",
    "    volumes[class_id] = volume_mm3\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nVolumes calculados:\")\n",
    "for class_id, volume in volumes.items():\n",
    "    print(f\"Classe {class_id} ({['CSF', 'GM', 'WM', 'Preto'][class_id]}): {volume:.2f} mm³\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o Kmeans++ com imagens sem normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "# --- Carregar a imagem original ---\n",
    "image_path = \"images_filtered\\IXI002-Guys-0828-T1.nii.gz\"  \n",
    "nifti_image = nib.load(image_path)\n",
    "image_data = nifti_image.get_fdata()\n",
    "\n",
    "# --- Carregar a máscara ---\n",
    "mask_path = \"atlas_resampled\\IXI002-Guys-0828-T1.nii.gz\\mni_mask.nii.gz\"\n",
    "mask_nifti = nib.load(mask_path)\n",
    "mask_data = mask_nifti.get_fdata()\n",
    "\n",
    "# --- Aplicar a máscara (mantendo apenas a parte branca) ---\n",
    "image_data[mask_data == 0] = 0\n",
    "\n",
    "# Obter o tamanho do voxel em mm³ (dimensão do voxel)\n",
    "voxel_size = np.prod(nifti_image.header.get_zooms())\n",
    "\n",
    "# Número de clusters (3 classes + 1 classe \"lixo\")\n",
    "k = 4\n",
    "\n",
    "# --- Inicialização dos centróides com K-means++ ---\n",
    "def initialize_kmeans_pp(data, k):\n",
    "    \"\"\"\n",
    "    Inicializa os centróides usando o método K-means++\n",
    "    \"\"\"\n",
    "    data_flat = data[mask_data > 0].flatten()  # Apenas valores dentro da máscara\n",
    "    centroids = [np.random.choice(data_flat)]  # Escolher o primeiro aleatoriamente\n",
    "    print(f' centroid inicial: { centroids}')\n",
    "    \n",
    "    for _ in range(1, k - 1):  # Deixar uma classe reservada para valores próximos de zero\n",
    "        distances = np.min([np.abs(data_flat - c) for c in centroids], axis=0)\n",
    "        probabilities = distances ** 2  # Quanto maior a distância, maior a chance de escolha\n",
    "        probabilities /= np.sum(probabilities)  # Normalizar\n",
    "        \n",
    "        new_centroid = np.random.choice(data_flat, p=probabilities)\n",
    "        centroids.append(new_centroid)\n",
    "    \n",
    "    centroids.append(0)  # Classe \"lixo\" para valores próximos de zero\n",
    "    \n",
    "    return np.array(centroids)\n",
    "\n",
    "# Inicializa os centróides\n",
    "centroids = initialize_kmeans_pp(image_data, k)\n",
    "\n",
    "# --- Função para atribuir cada pixel ao cluster mais próximo ---\n",
    "def assign_to_cluster(image_data, centroids):\n",
    "    distances = np.abs(image_data[..., None] - centroids.flatten())\n",
    "    return np.argmin(distances, axis=-1)\n",
    "\n",
    "# --- Função para atualizar os centroids ---\n",
    "def update_centroids(image_data, labels, k):\n",
    "    new_centroids = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        if np.any((labels == i) & (mask_data > 0)) and i != k - 1:  # Apenas valores dentro da máscara\n",
    "            new_centroids[i] = np.mean(image_data[(labels == i) & (mask_data > 0)])\n",
    "            print(f' new_centroids {[i]}: { new_centroids[i]}')\n",
    "        else:\n",
    "            new_centroids[i] = centroids[i]  # Mantém o valor se não houver atualização\n",
    "            print(f'centroids {[i]}: {centroids[i]}')\n",
    "            print(f' new_centroids {[i]}: { new_centroids[i]}')\n",
    "    return new_centroids\n",
    " \n",
    "\n",
    "# Número máximo de iterações\n",
    "max_iters = 100\n",
    "tolerance = 1e-4\n",
    "prev_centroids = np.zeros_like(centroids)\n",
    "\n",
    "# --- Iteração do K-means ---\n",
    "for iteration in range(max_iters):\n",
    "    labels = assign_to_cluster(image_data, centroids)\n",
    "    centroids = update_centroids(image_data, labels, k)\n",
    "    \n",
    "    if np.all(np.abs(centroids - prev_centroids) < tolerance):\n",
    "        print(f\"Convergência atingida após {iteration + 1} iterações.\")\n",
    "        break\n",
    "    \n",
    "    prev_centroids = centroids.copy()\n",
    "\n",
    "# Criar uma imagem RGB para visualização\n",
    "segmented_rgb = np.zeros((*labels.shape, 3), dtype=np.uint8)\n",
    "\n",
    "# Definir as cores (R, G, B)\n",
    "colors = {\n",
    "    0: [255, 0, 0],      # CSF\n",
    "    1: [128, 128, 128],      # GM\n",
    "    2: [255, 255, 255],  # WM\n",
    "    3: [0, 0,  0],  # Preto\n",
    "}\n",
    "\n",
    "# Atribuir cores aos pixels classificados\n",
    "for class_id, color in colors.items():\n",
    "    segmented_rgb[labels == class_id] = color\n",
    "\n",
    "# Aplicar a máscara na segmentação (fundo preto)\n",
    "segmented_rgb[mask_data == 0] = [0, 0, 0]\n",
    "\n",
    "# Mostrar um corte da segmentação\n",
    "slice_index = segmented_rgb.shape[0] // 2\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(segmented_rgb[slice_index])\n",
    "plt.title(\"Segmentação K-means++ com máscara aplicada\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# --- Cálculo do Volume ---\n",
    "volumes = {}\n",
    "for class_id in range(k):\n",
    "    num_voxels = np.sum((labels == class_id) & (mask_data > 0))\n",
    "    volume_mm3 = num_voxels * voxel_size\n",
    "    volumes[class_id] = volume_mm3\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nVolumes calculados:\")\n",
    "for class_id, volume in volumes.items():\n",
    "    print(f\"Classe {class_id} ({['CSF', 'GM', 'WM', 'Preto'][class_id]}): {volume:.2f} mm³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação dos resultados obtidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imagem sem normalização\n",
    "Volumes calculados:\n",
    "Classe 0 (CSF): 612731.84 mm³\n",
    "Classe 1 (GM): 275177.83 mm³\n",
    "Classe 2 (WM): 681555.30 mm³\n",
    "Classe 3 (Preto): 197074.20 mm³\n",
    "\n",
    "Volumes calculados:\n",
    "Classe 0 (CSF): 612731.84 mm³\n",
    "Classe 1 (GM): 275177.83 mm³\n",
    "Classe 2 (WM): 681555.30 mm³\n",
    "Classe 3 (Preto): 197074.20 mm³\n",
    "\n",
    "Volumes calculados:\n",
    "Classe 0 (CSF): 681555.30 mm³\n",
    "Classe 1 (GM): 612731.84 mm³\n",
    "Classe 2 (WM): 275177.83 mm³\n",
    "Classe 3 (Preto): 197074.20 mm³\n",
    "\n",
    "\n",
    "Imagem com normalização\n",
    "Volumes calculados:\n",
    "Classe 0 (Vermelho): 595731.00 mm³\n",
    "Classe 1 (Azul): 248577.00 mm³\n",
    "Classe 2 (Rosa): 643773.00 mm³\n",
    "Classe 3 (Cinza): 186864.00 mm³\n",
    "\n",
    "Volumes calculados:\n",
    "Classe 0 (Vermelho): 595731.00 mm³\n",
    "Classe 1 (Azul): 248577.00 mm³\n",
    "Classe 2 (Rosa): 643773.00 mm³\n",
    "Classe 3 (Cinza): 186864.00 mm³\n",
    "\n",
    "Volumes calculados:\n",
    "Classe 0 (Vermelho): 595731.00 mm³\n",
    "Classe 1 (Azul): 248577.00 mm³\n",
    "Classe 2 (Rosa): 643773.00 mm³\n",
    "Classe 3 (Cinza): 186864.00 mm³\n",
    "\n",
    "Volumes calculados:\n",
    "Classe 0 (Vermelho): 643773.00 mm³\n",
    "Classe 1 (Azul): 248577.00 mm³\n",
    "Classe 2 (Rosa): 595731.00 mm³\n",
    "Classe 3 (Cinza): 186864.00 mm³\n",
    "\n",
    "Volumes calculados:\n",
    "Classe 0 (CSF): 595731.00 mm³\n",
    "Classe 1 (GM): 248577.00 mm³\n",
    "Classe 2 (WM): 643773.00 mm³\n",
    "Classe 3 (Preto): 186864.00 mm³"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
